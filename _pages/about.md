---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am Yifan Jiang, a second-year Ph.D. student in Computer Science at the [University of Southern California, Information Science Institute (USC-ISI)](https://www.isi.edu/), where I specialize in Natural Language Processing (NLP), Commonsense Reasoning, Knowledge Graphs, and Machine Learning. I am currently working under the guidance of [Prof. Jay Pujara](https://www.jaypujara.org/index.html) at the [Knowledge Graph Center](https://www.isi.edu/centers-ckg/). Previously, I earned my Master's degree in Computer Science at USC, advised by [Prof. Filip Ilievski](https://www.ilievski.info/) and completed my Bachelor's degree at the [Southern University of Science and Technology (SUSTech)](https://www.sustech.edu.cn/en/), advised by [Prof. Xuan Song](https://sai.jlu.edu.cn/info/1094/4545.htm).

My primary research objective is to enhance the reasoning capabilities of AI systems in order to improve user interactions and move closer to the development of Artificial General Intelligence (AGI). I aim to develop models that emulate the diverse reasoning patterns found in human cognition, such as commonsense reasoning, abstract reasoning, analogical reasoning, and social intelligence. To achieve this, my research revolves around addressing three key questions:

- **How do models understand and interpret complex inputs?**ï¼š Whether models are able to distinguish useful information from noise or irrelevant data, enabling them to focus on the most relevant signals for accurate decision-making.

- **How do models reason and generate answers based on given conditions or contexts?**: Whether models can adapt their learned knowledge to different types of conditions: familiar scenarios (Known Known), unexpected situations (Known Unknown), and entirely novel contexts (Unknown Unknown) that may require flexible reasoning or generalization.

- **How can we evaluate that models truly understand the answer, rather than getting it through hallucination?**: Whether models can demonstrate a robust and faithful understanding of their answers, providing explanations grounded in verifiable knowledge rather than memorizing training samples, fabricating responses or relying on spurious correlations.

I was a research intern at <a href="https://www.amazon.com/gp/video/storefront" style="display: inline-flex; align-items: center;"><img src="../assets/amazon_logo.png" alt="Amazon Logo" style="height: 1em; margin-right: 0.3em;">Amazon & Amazon Prime Video</a> (2025 with [Rui Zhao](https://www.linkedin.com/in/rui-zhao-7855ab26/) and [Yueying Wang](https://www.linkedin.com/in/yueying-wang-stat/)), <a href="https://www.hippocraticai.com/" style="display: inline-flex; align-items: center;"><img src="../assets/main-hippocratic-logo-full-color.png" alt="Hippocratic AI Logo" style="height: 1em; margin-right: 0.3em;">Hipporcratic AI</a> (2024 with [Subhabrata Mukherjee](https://subhomukherjee.com/) and [Kriti Aggarwal](https://www.linkedin.com/in/kriti-agg/)).



## <span style="color: #4682B4;">News</span>
- **<span style="color: #1E90FF;">[2025-08-20]</span>** One paper: [<span style="color: #2E8B57;">**Recent Advances in Large Langauge Model Benchmarks against Data Contamination: From Static to Dynamic Evaluation**</span>](https://arxiv.org/abs/2502.17521) has been accepted to [<span style="color: #8A2BE2;">**EMNLP 2025**</span>](https://2025.emnlp.org/)!
- **<span style="color: #1E90FF;">[2025-08-14]</span>** Honored to be invited by [<span style="color: #8A2BE2;">**Salesforce AI Research**</span>](https://www.salesforceairesearch.com/publications) to join the [<span style="color: #2E8B57;">**Salesforce AI Research Future Forum**</span>](https://www.linkedin.com/feed/update/urn:li:activity:7363972366336421888/) and share our work on [**abstraction reasoning**</span>](https://proceedings.neurips.cc/paper_files/paper/2024/hash/529d8b3a23991e83db07f21727256374-Abstract-Datasets_and_Benchmarks_Track.html). 
- **<span style="color: #1E90FF;">[2025-05-15]</span>** One first-authored paper: [<span style="color: #2E8B57;">**RED QUEEN: Safeguarding Large Language Models against Concealed Multi-Turn Jailbreaking**</span>](https://arxiv.org/abs/2409.17458) has been accepted to [<span style="color: #8A2BE2;">**ACL 2025 Findings**</span>](https://2025.aclweb.org/)!
- **<span style="color: #1E90FF;">[2024-12-10]</span>** One paper: [<span style="color: #2E8B57;">**COLUMBUS: Evaluating COgnitive Lateral Understanding through Multiple-choice reBUSes**</span>](https://ojs.aaai.org/index.php/AAAI/article/view/32464) has been accepted to [<span style="color: #8A2BE2;">**AAAI 2025**</span>](https://aaai.org/conference/aaai/aaai-25/)!
- **<span style="color: #1E90FF;">[2024-10-07]</span>** One first-authored paper: [<span style="color: #2E8B57;">**MARVEL: Multidimensional Abstraction and Reasoning through Visual Evaluation and Learning**</span>](https://proceedings.neurips.cc/paper_files/paper/2024/hash/529d8b3a23991e83db07f21727256374-Abstract-Datasets_and_Benchmarks_Track.html) has been accepted to [<span style="color: #8A2BE2;">**NeurIPS 2024**</span>](https://neurips.cc/)!
- **<span style="color: #1E90FF;">[2024-09-23]</span>** Our research is highlighted in this [<span style="color: #FF4500;">**BBC article**</span>](https://www.bbc.com/future/article/20240912-what-riddles-teach-us-about-the-human-mind)!
- **<span style="color: #1E90FF;">[2024-07-10]</span>** One paper: [<span style="color: #2E8B57;">**The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large Language Models**</span>](https://arxiv.org/abs/2401.12117) has been accepted to [<span style="color: #8A2BE2;">**COLM 2024**</span>](https://colmweb.org/)!
- **<span style="color: #1E90FF;">[2024-04-29]</span>** One paper: [<span style="color: #2E8B57;">**ARN: Analogical Reasoning on Narratives**</span>](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00688/124260/ARN-Analogical-Reasoning-on-Narratives) has been accepted to [<span style="color: #8A2BE2;">**TACL**</span>](https://transacl.org/index.php/tacl)!
- **<span style="color: #1E90FF;">[2023-11-28]</span>** One paper: [<span style="color: #2E8B57;">**FIRE: Food Image to REcipe Generation**</span>](https://openaccess.thecvf.com/content/WACV2024/html/Chhikara_FIRE_Food_Image_to_REcipe_Generation_WACV_2024_paper.html) has been accepted to [<span style="color: #8A2BE2;">**WACV 2024**</span>](https://wacv2024.thecvf.com/)!
- **<span style="color: #1E90FF;">[2023-10-07]</span>** One first-authored paper: [<span style="color: #2E8B57;">**BRAINTEASER: Lateral Thinking Puzzles for Large Language Models**</span>](https://arxiv.org/abs/2310.05057) has been accepted to [<span style="color: #8A2BE2;">**EMNLP 2023**</span>](https://2023.emnlp.org/)!
- **<span style="color: #1E90FF;">[2023-07-15]</span>** One first-authored paper: [<span style="color: #2E8B57;">**Transferring Procedural Knowledge across Commonsense Tasks**</span>](https://arxiv.org/abs/2304.13867) _(oral+poster)_ has been accepted to [<span style="color: #8A2BE2;">**ECAI 2023**</span>](https://ecai2023.eu/ECAI2023)!
- **<span style="color: #1E90FF;">[2023-06-16]</span>** One first-authored paper: [<span style="color: #2E8B57;">**SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common Sense**</span>](https://arxiv.org/abs/2404.16068) has been accepted to [<span style="color: #8A2BE2;">**SemEval 2024@NAACL**</span>](https://semeval.github.io/SemEval2024/cft)!
- **<span style="color: #1E90FF;">[2023-01-14]</span>** One paper: [<span style="color: #2E8B57;">**TrafPS: A Shapley-based Visual Analytics Approach to Interpret Traffic**</span>](https://arxiv.org/abs/2404.16068) has been accepted to [<span style="color: #8A2BE2;">**CVMJ**</span>](https://www.editorialmanager.com/cvmj/default.aspx)!


<!--
- **[2024-10-07]** One first-authored [paper](https://arxiv.org/abs/2404.13591) has been accepted to [NeurIPS 2024](https://neurips.cc/)!
- **[2024-07-10]** One [paper](https://arxiv.org/abs/2401.12117) has been accepted to [COLM 2024](https://colmweb.org/)!
- **[2024-04-29]** One [paper](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00688/124260/ARN-Analogical-Reasoning-on-Narratives) has been accepted to [TACL](https://transacl.org/index.php/tacl)!
- **[2023-11-28]** One [paper](https://openaccess.thecvf.com/content/WACV2024/html/Chhikara_FIRE_Food_Image_to_REcipe_Generation_WACV_2024_paper.html) has been accepted to [WACV 2024](https://wacv2024.thecvf.com/)!
- **[2023-10-07]** One first-authored [paper](https://arxiv.org/abs/2310.05057) has been accepted to [EMNLP 2023](https://2023.emnlp.org/)!
- **[2023-07-15]** One first-authored [paper](https://arxiv.org/abs/2304.13867) (_oral+poster_) have been accepted to [ECAI 2023](https://ecai2023.eu/ECAI2023)!
- **[2023-06-16]** One first-authored [paper](https://arxiv.org/abs/2404.16068) have been accepted to [SemEval 2024@NAACL](https://semeval.github.io/SemEval2024/cft)!
- **[2023-01-14]** One [paper](https://arxiv.org/abs/2404.16068) have been accepted to [CVMJ](https://www.editorialmanager.com/cvmj/default.aspx)!
-->








